<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>&lt;img src=&#39;https://arunkoundinya.github.io/AIBasicswithAK/logo.png&#39; style=&#39;width: 2.2em; height: 2.2em; border-radius: 30%;&#39;&gt; &lt;b&gt;AI Basics with AK&lt;/b&gt;</title>
<link>https://arunkoundinya.github.io/AIBasicswithAK/blogs/</link>
<atom:link href="https://arunkoundinya.github.io/AIBasicswithAK/blogs/index.xml" rel="self" type="application/rss+xml"/>
<description>LETS BREATHE DATA</description>
<generator>quarto-1.7.30</generator>
<lastBuildDate>Sun, 23 Feb 2025 05:00:00 GMT</lastBuildDate>
<item>
  <title>Representation Models - Text Classification</title>
  <dc:creator>Arun Koundinya Parasa</dc:creator>
  <link>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/representation_models/</link>
  <description><![CDATA[ 





<p>In the previous article, we explored the <code>master chef</code> analogy for foundation models. We also discussed how <code>transformers</code> serve as the basic architecture for <code>large language models</code>. Depending on which part of the transformer model is used — <code>encoder</code> or <code>decoder</code>— we have two types of LLMs: <code>representation models</code>, which represent words as numbers, and <code>generative models</code>, which generate text.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/representation_models/image.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" width="568"></p>
</figure>
</div>
<p>In this article we will go through these topics in simpler language:</p>
<ul>
<li>What are Reprensentation Models?</li>
<li>What is BERT ?</li>
<li>What is Sentence Transformers?</li>
</ul>
<section id="what-are-representation-models" class="level3">
<h3 class="anchored" data-anchor-id="what-are-representation-models">What are Representation Models?</h3>
<p>Imagine stepping into a vast library where every book is catalogued not just by its title but by the essence of its content. Representation models work in a similar way. They convert text—be it a word, a sentence, or a whole document—into a series of numbers, often referred to as vectors. These vectors serve as unique fingerprints, capturing the context, sentiment, and meaning embedded within the text.</p>
<p>By transforming text into these numerical fingerprints, representation models empower machines to perform tasks like text classification, sentiment analysis, and topic detection without needing to understand language in the traditional sense. In short, they provide a foundational layer that bridges raw text and actionable insights.</p>
</section>
<section id="what-is-bert" class="level3">
<h3 class="anchored" data-anchor-id="what-is-bert">What is BERT?</h3>
<p>BERT, which stands for <strong>Bidirectional Encoder Representations from Transformers</strong>, is one of the most influential models in NLP. Developed by Google, BERT revolutionized language understanding by taking context into account from both directions—left and right of each word.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/representation_models/NSP.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="617"></p>
</figure>
</div>
<p>Here’s what makes BERT stand out:</p>
<ul>
<li><strong>Bidirectional Context:</strong> Unlike earlier models that read text in a single direction, BERT examines the entire sentence simultaneously, ensuring a richer and more nuanced understanding of word meanings.</li>
<li><strong>Massive Pre-training:</strong> BERT is trained on extensive datasets using innovative tasks like Masked Language Modeling (MLM) and Next Sentence Prediction (NSP), which allow it to learn intricate language patterns.</li>
<li><strong>Versatility:</strong> From text classification and sentiment analysis to question answering, BERT’s robust representations make it adaptable to a wide range of NLP tasks.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/representation_models/MLM.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="611"></p>
</figure>
</div>
<p>Think of BERT as a master chef who not only knows every ingredient (word) in a recipe (sentence) but also understands how they all interact to create the perfect flavor (meaning).</p>
</section>
<section id="what-is-sentence-transformers" class="level3">
<h3 class="anchored" data-anchor-id="what-is-sentence-transformers">What is Sentence Transformers?</h3>
<p>While BERT provides deep contextual understanding at the word and sentence level, Sentence Transformers are tailored to generate fixed-size embeddings for entire sentences. These embeddings make it easier to compare, cluster, and classify text based on semantic similarity.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/representation_models/ST.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
<p>Key aspects of Sentence Transformers include:</p>
<ul>
<li><strong>Pre-Training:</strong> Sentence Transformers are also called as SBERT is fine-tuned on sentence pairs using siamese architecture as show in above image.</li>
<li><strong>Efficient Semantic Comparison:</strong> By mapping sentences to a common vector space, these models enable quick and accurate comparisons—essential for tasks like semantic search and clustering.</li>
<li><strong>Enhanced Text Classification:</strong> Converting sentences into embeddings simplifies the process of sorting texts into categories, as similar sentences will have similar vector representations.</li>
<li><strong>Real-World Applications:</strong> From grouping similar customer reviews to organizing news articles, Sentence Transformers provide a robust framework for handling diverse text classification challenges.</li>
</ul>
<p>Imagine Sentence Transformers as a refined culinary tool that not only identifies each ingredient but also captures the overall recipe. Ideally, Sentence Transformers create better embeddings since it captures the context of overall recipe rather than at ingredient levels.</p>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>Representation models are the unsung heroes behind many NLP applications, transforming raw text into meaningful data that machines can understand. BERT and Sentence Transformers exemplify how far we’ve come—each offering unique advantages in capturing the subtle nuances of language. Whether it’s for text classification or broader language understanding tasks, these models continue to push the boundaries of what’s possible in AI.</p>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li><a href="https://medium.com/@mroko001/transformers-in-nlp-bert-and-sentence-transformers-3faab61918ea">Transformers in NLP: BERT and Sentence Transformers</a></li>
<li><a href="https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/">Hands-On Large Language Models by Jay Alammar, Maarten Grootendorst</a></li>
<li>ChatGPT For Refining Language.</li>
<li><a href="https://swatimeena989.medium.com/bert-text-classification-using-keras-903671e0207d">BERT Text Classification using Keras</a></li>
<li><a href="https://www.marqo.ai/course/introduction-to-sentence-transformers#3-sentence-transformers">Introduction to Sentence Transformers</a></li>
</ul>
<script src="https://giscus.app/client.js" data-repo="ArunKoundinya/AIBasicswithAK" data-repo-id="R_kgDOLXPVRw" data-category="General" data-category-id="DIC_kwDOLXPVR84CdeVx" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="purple_dark" data-lang="en" crossorigin="anonymous" async="">
</script>


</section>

 ]]></description>
  <category>nlp</category>
  <category>llm</category>
  <category>deeplearning</category>
  <guid>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/representation_models/</guid>
  <pubDate>Sun, 23 Feb 2025 05:00:00 GMT</pubDate>
  <media:content url="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/representation_models/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Foundation Models - LLMs</title>
  <dc:creator>Arun Koundinya Parasa</dc:creator>
  <link>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/foundation-models-llm/</link>
  <description><![CDATA[ 





<p>In an era of chatgpt-enabled applications, most of us would have come across a term called as <code>foundation model</code>. In this article we will go through the basics of <code>foundation model</code> with respect to <code>Large Language Models</code></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/foundation-models-llm/image.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="568"></p>
</figure>
</div>
<p>In this article we will go through these topics in simple language:</p>
<ul>
<li>What are Foundation Models?</li>
<li>What are Large Language Models?</li>
<li>Fundamental Architecture inside LLM?</li>
<li>Types of LLMs.</li>
</ul>
<section id="what-are-foundation-models" class="level3">
<h3 class="anchored" data-anchor-id="what-are-foundation-models">What are Foundation Models?</h3>
<p>If you go to any <code>Indian restaurant</code> and order <code>Chicken Tikka Masala</code>, it arrives at your table in no time. But if you were to make the same dish from scratch, it would take much longer. Most people assume that restaurants prepare curries in advance and simply reheat them when an order comes in. However, that would be a waste of resources if there aren’t any orders for that particular dish.</p>
<p>Instead, restaurants use a common base gravy for a wide range of curries—such as <code>Onion-Tomato Gravy</code> or <code>Onion-Spinach-Ginger Gravy</code>. When an order hits the kitchen, chefs take this foundation gravy, add the required proteins, herbs, and veggies, and create a distinct curry as per the order. This approach saves time, ensures consistency, and allows for quick adaptation to different recipes.</p>
<p>Now, we can apply this analogy to our <code>AI models</code>.</p>
<p><code>Foundation Models</code> are like these base gravies. They are trained on vast amounts of data and serve as a starting point for a range of applications. Unlike a base gravy, where we choose common ingredients, foundation models are built by training on diverse and extensive datasets.</p>
<p>For example, in <code>Natural Language Processing</code> (NLP), which deals with human language and conversation, a foundation model is trained on massive amounts of text data available on the internet (while ensuring ethical considerations). The resulting model acts as a foundation for various NLP tasks, such as <code>chatbots</code>, <code>translations</code>, and <code>text generation</code>.</p>
<p>Just like chefs fine-tune a <code>base gravy</code> to create <code>different dishes</code>, developers <code>fine-tune foundation models</code> to adapt them for <code>specific use cases</code>.</p>
</section>
<section id="what-are-large-language-models" class="level3">
<h3 class="anchored" data-anchor-id="what-are-large-language-models">What are Large Language Models?</h3>
<p><code>Large Language Models</code> is one such <code>foundation model</code> that is trained on vast textual data using <code>Deep Learning</code> to understand and generate human type of language.</p>
<p>Much like our <code>foundation gravy</code>, <code>LLMs</code> act as a foundation for language-based applications. Instead of training a model from scratch for every NLP task, we build on this pre-trained foundation model and fine-tune them for specific purposes.</p>
</section>
<section id="fundamental-architecture-inside-llm" class="level3">
<h3 class="anchored" data-anchor-id="fundamental-architecture-inside-llm">Fundamental Architecture inside LLM?</h3>
<p>At the heart of <code>LLMs</code> lies the <code>Transformer architecture</code>, introduced in the groundbreaking paper <code>"Attention is All You Need"</code> by Vaswani et al.&nbsp;This architecture revolutionized NLP as this model helps to understand context and relationships between words more effectively.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/foundation-models-llm/transformer.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="371"></p>
</figure>
</div>
<p>The original paper was developed for a <code>language translation</code> use case. The input is in one language, say English, and the output is in another language, say Hindi. The blue section represents the <code>Encoder</code>, while the red section represents the <code>Decoder</code>.</p>
<ol type="1">
<li>The <code>Encoder</code> is responsible for understanding the input language.</li>
<li>The <code>Decoder</code> then generates the output language by interpreting the encoded information.</li>
</ol>
<p>This encoder-decoder framework laid the foundation for many modern NLP models, enabling efficient translation, text generation, and other complex language tasks.</p>
</section>
<section id="types-of-llms" class="level3">
<h3 class="anchored" data-anchor-id="types-of-llms">Types of LLMs?</h3>
<p>Since the original encoder-decoder architecture was designed for translation tasks, it is not ideally suited for other tasks like text classification, topic selection, generative tasks, and more.</p>
<section id="encoder-only-llm---representation-models" class="level4">
<h4 class="anchored" data-anchor-id="encoder-only-llm---representation-models">Encoder Only LLM - Representation Models</h4>
<p>To address this, a general-purpose model was introduced in 2018: <code>Bidirectional Encoder Representations from Transformers</code> (BERT). This model served as a foundational architecture for Language AI in the years to come.</p>
<ul>
<li>The <code>Encoder-only</code> architecture focuses on understanding and representing language rather than generating it.</li>
<li>It learns the nuances and contextual <code>representations of language</code> effectively.</li>
<li>Ideal for tasks that require deep language comprehension.</li>
</ul>
</section>
<section id="decoder-only-llm---generative-models" class="level4">
<h4 class="anchored" data-anchor-id="decoder-only-llm---generative-models">Decoder Only LLM - Generative Models</h4>
<p>Similar to the <code>Encoder-only</code> architecture, a <code>Decoder-only</code> architecture was proposed in 2018 for generative tasks. This model is known as <code>Generative Pre-trained Transformer</code> (GPT).</p>
<ul>
<li>The <code>Decoder-only</code> architecture is designed to generate text based on a given prompt or input.</li>
<li>It is widely used for conversational AI, creative writing, and content generation.</li>
</ul>
<p>Thus, these two foundational LLM architectures are broadly used for a variety of applications today.</p>
</section>
</section>
<section id="use-cases." class="level3">
<h3 class="anchored" data-anchor-id="use-cases.">Use Cases.</h3>
<p>Encoder-Only LLMs (BERT and similar models):</p>
<ul>
<li>Text classification</li>
<li>Sentiment analysis</li>
<li>Information retrieval</li>
<li>Question answering</li>
</ul>
<p>Decoder-Only LLMs (GPT and similar models):</p>
<ul>
<li>Text generation</li>
<li>Conversational AI (chatbots, virtual assistants)</li>
<li>Summarization</li>
</ul>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Foundation_model">Foundation_model - Wiki Page</a></li>
<li><a href="https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/">Hands-On Large Language Models by Jay Alammar, Maarten Grootendorst</a></li>
</ul>
<script src="https://giscus.app/client.js" data-repo="ArunKoundinya/AIBasicswithAK" data-repo-id="R_kgDOLXPVRw" data-category="General" data-category-id="DIC_kwDOLXPVR84CdeVx" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="purple_dark" data-lang="en" crossorigin="anonymous" async="">
</script>


</section>

 ]]></description>
  <category>nlp</category>
  <category>llm</category>
  <category>deeplearning</category>
  <guid>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/foundation-models-llm/</guid>
  <pubDate>Sat, 15 Feb 2025 05:00:00 GMT</pubDate>
  <media:content url="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/foundation-models-llm/image.png" medium="image" type="image/png" height="85" width="144"/>
</item>
<item>
  <title>What metrics to be chosen for classification modelling?</title>
  <dc:creator>Arun Koundinya Parasa</dc:creator>
  <link>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/</link>
  <description><![CDATA[ 





<p>This blog is a response to my teammates’ questions on <code>WhatsApp</code>. I’m sharing what I learned and my views on each question in a separate blog.</p>
<p>The biggest challenge in classification modelling is choosing the right metric for our problem. Adding to this, the confusion matrix creates more confusion for us as it has more metrics than we imagine.</p>
<p>Let’s cut short this, Arun. Ask for <code>GenAI</code> tools; we rely on them.</p>
<p>Go through this <code>ChatGPT</code> link <a href="https://chat.openai.com/share/44e15e4f-ed46-49e4-97c7-232d98a3006c">response</a>. It will not help. Why?</p>
<p>Arun! prompt has to be more specific.</p>
<p>Okay! Okay! Here is a revised prompt <a href="https://chat.openai.com/share/353267af-3dc4-449b-b0a1-2c4124a08ffe">response</a> from <code>ChatGPT</code>. Still, It doesn’t help. Why?</p>
<p>It is because we, humans, need to decide what the right metric is. For this, <code>Data Scientists</code> need to step up and do three essential things which are usually not in their comfort zone:</p>
<ul>
<li>Speak to business stakeholders and understand their purpose again.</li>
<li>Also, understand how they will use our predictions.</li>
<li>Finally, before jumping into modelling and its coding, check whether the dependent variable is defined per the business purpose and its corresponding usage.</li>
</ul>
<p>Step three is the recipe for experience, i.e., multiple tries and failures, which this blog will not discuss.</p>
<section id="confusion-matrix" class="level2">
<h2 class="anchored" data-anchor-id="confusion-matrix">1. Confusion Matrix</h2>
<p>Understanding the details of the <code>Confusion Matrix</code> is fundamental.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/confusion.png" class="img-fluid figure-img" width="857"></p>
<figcaption>Source : https://en.wikipedia.org/wiki/Confusion_matrix</figcaption>
</figure>
</div>
<p>The top four boxes are the result of prediction vs actual. The remaining boxes are divided metrics based on the numbers.</p>
<p>At this point in this blog, let’s not delve into these multiple metrics, as there are many :).</p>
</section>
<section id="simpler-thumb-rules" class="level2">
<h2 class="anchored" data-anchor-id="simpler-thumb-rules">2. Simpler Thumb Rules</h2>
<p>The more straightforward thumb rule is to print the classification report from sci-kit Learn and use one of these metrics for our classification modelling. This is an excellent place to start, as most of the ML problems we solve commercially fall into these four metrics.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/classification_report_python.png" width="400" height="147" class="figure-img"></p>
<figcaption>Source : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html</figcaption>
</figure>
</div>
<p>In most classification problems, the <code>target</code> class would be either a <code>positive</code> or <code>negative</code>; under this content, let us review the intuition behind these metrics.</p>
<section id="accuracy" class="level3">
<h3 class="anchored" data-anchor-id="accuracy">2.1. Accuracy</h3>
<p>In more straightforward English, it is how accurate you are. If there are <code>50 positive</code> and <code>50 negative</code> instances, accuracy measures how many times the model is able to predict accurately the right instances out of these 100 original instances.</p>
<p>If the model can correctly predict <code>30 positive</code> and <code>50 negative</code> instances, it means that the model’s accuracy is 80 correctly predicted instances out of the total 100 cases.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/cm-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Using this metric is always a problem as there is a high chance of giving more accuracy under imbalanced class scenarios.</p>
<p>If there are <code>5 positive</code> instances and <code>95 negative</code> instances and model-1 can predict <code>0 positive</code> instances and <code>85 negative</code> instances, we say that model-1 has 85% accuracy. While model-2 can predict four positive instances and <code>79 negative</code> instances, we say that model-2 has 83% accuracy.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/cm-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>When we look at the accuracy metric without having the context of our data, we may choose a poor model-1, which has higher accuracy.</p>
</section>
<section id="recall" class="level3">
<h3 class="anchored" data-anchor-id="recall">2.2. Recall:</h3>
<p>In more straightforward English, recall is how much your model can recall the scenario. In a binary classification model, we usually refer to recall to the positive class to ensure that the model recalls the maximum positive instances. It calculates the proportion of true positive predictions among all actual positive instances.</p>
<p>Returning to our earlier example, which model is better off if there are <code>5 positive</code> instances and <code>95 negative</code> instances for model-1 and model-2?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/cm-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Here, if we want to be sure that the number of predicted positive instances upon actual positive instances should be more, we will select model-2 instead of model-1.</p>
<p>Now, let’s go back to our first example again, which is that there are <code>50 positive</code> instances and <code>50 negative</code> instances, and model-1 is able to predict <code>15 positive</code> instances and <code>50 negative</code> instances. Here, model 1 has almost 65% accuracy and a recall of 30% for positive instances. Similarly, model 2 can predict <code>25 positive</code> and <code>50 negative</code> instances. Here, model 2 has almost 65% accuracy and a recall of 50% for positive cases.</p>
<p>Model 2 is better when we look into recall metrics. Isn’t it so?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/cm-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>But, when completing the entire confusion matrix, it might look like this: do you see something off? What is the catch?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/cm-4.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Model-1 doesn’t have any false alarms, which means the model-1 is more precise in predicting positive instances.</p>
</section>
<section id="precision" class="level3">
<h3 class="anchored" data-anchor-id="precision">2.3. Precision:</h3>
<p>In more straightforward English, precision is the degree to which the model is precise, like hitting a bull’s eye for positive instances. High precision signifies a low false positive rate. Mathemically it is like ratio of true positive predictions to the total positive predictions made by the model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/cm-4.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Under this scenario, model 1 is more precise.</p>
</section>
<section id="f1-score" class="level3">
<h3 class="anchored" data-anchor-id="f1-score">2.4. F1-Score:</h3>
<p>F1-Score is the harmonic mean of precision and recall. It provides a balance between precision and recall, making it a useful metric when there’s an uneven class distribution. A high F1-Score indicates both high precision and high recall.</p>
<p>Usually, while developing model we stick to one metric.</p>
</section>
</section>
<section id="why-stick-to-one-metric" class="level2">
<h2 class="anchored" data-anchor-id="why-stick-to-one-metric">3. Why stick to one metric?</h2>
<p>Often, rather than sticking to one model, it is wise to prepare multiple models, optimize them using the development dataset, and use the test set for the final performance. So, while optimizing and evaluating the models, it is advisable to stick to one metric because we cannot have different barometers for each model.</p>
</section>
<section id="how-to-choose" class="level2">
<h2 class="anchored" data-anchor-id="how-to-choose">4. How to Choose</h2>
<p>This part of the blog is the prime Purpose, which depends upon the two questions that <code>Data Scientists</code> need to ask the business stakeholders i.e.; Purpose and usage. Purpose gives the revenue for the model, and usage tells us the cost.</p>
<p>How come?</p>
<p>Let’s dwell on some examples.</p>
<section id="example---cross-sell" class="level3">
<h3 class="anchored" data-anchor-id="example---cross-sell">4.1. Example - Cross-Sell</h3>
<p><strong>Purpose</strong> - Identify Customers who can buy <code>Product1</code>. <strong>Usage1</strong> - Digital Campaigns ( Machine to Human ) <strong>Usage2</strong> - Non-Digital Campaigns ( Human to Human )</p>
<p>If we look at the Purpose, we might think <code>accuracy</code> would be sufficient to predict whether a customer will buy a particular product. This is the usual de facto approach we think.</p>
<p>Now, depending on usage, we need to optimize the metric, as it also tells us the cost of the usage.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/Example-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Usage1 -&gt; Usually, digital campaigns are low-cost. We want to be sure to reach as many right customers as possible at a low cost. So, in this scenario, it is better to optimize the models using <code>recall</code> since we don’t want to miss the right customer.</p>
<p>Usage2 -&gt; Usually, in non-digital campaigns, the cost is higher, and since the interaction is between humans, we have to ensure the trust chain of the model carries forward to the field team. So, in this scenario, it is better to optimize models using the <code>precision</code> metric.</p>
</section>
<section id="example---customer-attrition" class="level3">
<h3 class="anchored" data-anchor-id="example---customer-attrition">4.2. Example - Customer Attrition</h3>
<p><strong>Purpose</strong> - Identify Customers who would stop transacting <strong>Usage1</strong> - Carrot Communication in Digital way ( Machine to Human ) - Incentive <strong>Usage2</strong> - Carrot Communication in Non-Digital way ( Human to Human ) - Incentive</p>
<p>If we look at the Purpose, we might think <code>accuracy</code> would be sufficient as we just want to predict whether a customer would at-rite. This is the usual de facto approach we would think.</p>
<p>Now, depending on usage, let’s optimize the metric.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/Example-2.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Usage1 -&gt; Although digital campaigns are low-cost here, we need to ensure we predict all customers who will at-rite and give-away fewer incentives to the customers who actually don’t at-rite. So, in this scenario, it is better to optimize the models using the <code>F1-Score</code> metric.</p>
<p>Usage2 -&gt; Since trust-chain matters a lot in non-digital campaigns, apart from cost, it is better to optimize models using the <code>precision</code> metric.</p>
</section>
<section id="example---fraudulent-transaction" class="level3">
<h3 class="anchored" data-anchor-id="example---fraudulent-transaction">4.3. Example - Fraudulent Transaction</h3>
<p><strong>Purpose</strong> - Identify Customers’ accounts of fraudulent activity. <strong>Usage1</strong> - Digital Alarm ( Machine to Human ) <strong>Usage2</strong> - Non-Digital Alarm ( Human to Human )</p>
<p>If we just look at the Purpose, we might think that by default, we will select the <code>Precision</code> metric to ensure that fraudulent activity is arrested.</p>
<p>Now, depending on usage, let’s optimize the metric.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/Example-3.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Usage1 -&gt; Since digital campaigns are low-cost here, we must ensure we predict all fraudulent activities with fewer false alarms. So, it is better to optimize the model with <code>F1-Score</code>.</p>
<p>Usage2 -&gt; Since cost and trust-chain until customer matters a lot in non-digital campaigns, it is better to optimize models using the <code>precision</code> metric. However, in some scenarios <code>F1-Score</code> can be used if it is digitally assisted.</p>
<p>So, to summarize, we need to optimize the model based on the chosen metric of Purpose and usage, which is highly based on the context and business usage.</p>
</section>
</section>
<section id="can-we-change-the-metric-if-model-perform-is-poor" class="level2">
<h2 class="anchored" data-anchor-id="can-we-change-the-metric-if-model-perform-is-poor">5. Can we change the metric if model perform is poor?</h2>
<p>If we are unable to make goals, it is never advisable to change our goalpost. We always need to understand whether the goal post design is correct and then practice to make goals.</p>
</section>
<section id="further-discussions" class="level2">
<h2 class="anchored" data-anchor-id="further-discussions">6. Further Discussions</h2>
<p>Macro-average and weighted-average are not discussed here, which are better suited for discussing classification models with multiple class outcomes instead of binary ones.</p>
<script src="https://giscus.app/client.js" data-repo="ArunKoundinya/AIBasicswithAK" data-repo-id="R_kgDOLXPVRw" data-category="General" data-category-id="DIC_kwDOLXPVR84CdeVx" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="purple_dark" data-lang="en" crossorigin="anonymous" async="">
</script>


</section>

 ]]></description>
  <category>classification</category>
  <category>modelling</category>
  <category>metrics</category>
  <category>binaryclassifcation</category>
  <guid>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/</guid>
  <pubDate>Wed, 10 Apr 2024 04:00:00 GMT</pubDate>
  <media:content url="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/metrics-classification-model/confusion.png" medium="image" type="image/png" height="89" width="144"/>
</item>
<item>
  <title>Does Data Scientists need to learn programming?</title>
  <dc:creator>Arun Koundinya Parasa</dc:creator>
  <link>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/learn-programming/</link>
  <description><![CDATA[ 





<p>In an era of AI-enabled applications, chats, and programming (<a href="https://www.cognition-labs.com/blog-posts">now with Devin</a>), many youngsters and new entrants in the data science field assume that learning programming isn’t needed as almost all codes are available either on stack overflow or ChatGPT.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/learn-programming/image.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="373"></p>
</figure>
</div>
<p>However, programming is not just a copy-and-paste activity. But it is an iterative process of four pieces:</p>
<ul>
<li>What to Code?</li>
<li>How to Code?</li>
<li>Test the Code?</li>
<li>Coding with-in limitations.</li>
</ul>
<p>Here, <code>What to Code</code> can be comprehended as an <code>Ideaation/Requirement Gathering and Planning</code> stage. Ideas can be either intrinsic or extrinsic, but the primary reward goes to both, i.e., the idea and proper planning. This is itself an intensive area where the know-how of coding is required; otherwise, the entire planning and further execution would fall into a fallacy.</p>
<p><code>How to Code</code> involves the <code>Coding the requirement, unit-testing and documentation</code> stage. Coding becomes an iterative step along with unit testing since our code changes should not hamper that part of the unit.</p>
<p><code>Test the Code</code> involves <code>Reviewing the code and completing the system-testing</code> stage. After we complete our code, it needs to be reviewed and refined by a senior programmer, ideally with an intention to optimize its performance and ensure that this particular fix will not hamper other units in the system.</p>
<p><code>Coding within limitation</code> involves the <code>Deployment and Maintenance</code> stage. After the entire coding, testing, and documentation are completed, Deployment becomes a central learning as initial programming doesn’t involve physical limitations. Deployment limitations, becomes an iterative process to enhance our coding.</p>
<p>If we understand this complete cycle of programming, we will learn that coding is not just a copy-paste job but often requires a thought process for maintenance of the code for long-term usage. However, there might be some applications ( we can term such applications as <code>AI-assisted</code> programming applications ) in the future that would help automate some of these. Still, it would require a keen human eye and thought process for thorough Deployment.</p>
<p>If you heard about Scrum masters or Scrum certification it is good else google it. These people are often valued because they are aware of the fundamentals of agile methodological practices, which involve iterative steps of planning, coding, testing, and maintenance.</p>
<section id="some-future-or-current-technologies" class="level5">
<h5 class="anchored" data-anchor-id="some-future-or-current-technologies">Some Future or Current Technologies</h5>
<ul>
<li>Coding Assistant:
<ul>
<li>Code Autocompletion ; Example: Github Copilot</li>
<li>AI Driven Automation Testing; Example: Testim</li>
</ul></li>
<li>Minimal Coding:
<ul>
<li>Low-Code Platform ; Example: Microsoft Power Apps</li>
<li>No-Code Platform; Example: Bubble, Google AppSheet</li>
</ul></li>
<li>Power Computing:
<ul>
<li>Serverless Computing ; Example: AWS Lambda</li>
<li>Edge Computing; Example: AWS IoT</li>
<li>Quantum Computing; Example: IBM Quantum</li>
</ul></li>
</ul>
<p>View them as assistants that will fasten our process such that a particular idea’s “time to market” will come down exponentially.</p>
<script src="https://giscus.app/client.js" data-repo="ArunKoundinya/AIBasicswithAK" data-repo-id="R_kgDOLXPVRw" data-category="General" data-category-id="DIC_kwDOLXPVR84CdeVx" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="purple_dark" data-lang="en" crossorigin="anonymous" async="">
</script>


</section>

 ]]></description>
  <category>programming</category>
  <guid>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/learn-programming/</guid>
  <pubDate>Sun, 17 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/learn-programming/image.png" medium="image" type="image/png" height="123" width="144"/>
</item>
<item>
  <title>Does Data Scientists need to understand Domain Knowledge?</title>
  <dc:creator>Arun Koundinya Parasa</dc:creator>
  <link>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/is-domain-knowledge-important/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/is-domain-knowledge-important/image.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="439"></p>
</figure>
</div>
<p>This article intends to explain domain knowledge’s importance to freshers. The example provided below is from my own experience.</p>
<p>Businesses, by nature, want to earn profits, and why is it needed to make profits? From an employee perspective, the company gives salary and growth; from a company perspective, it intends to stay long, live and fresh as it grows.</p>
<p>Profit = Revenue - Cost</p>
<p>If the business needs to stay longer, the profit has to be on the positive side. It means either the revenue should increase or the cost should decrease; also, both can happen.</p>
<p>Let us explore simple business case scenarios that will help us learn why understanding the business comes first before we solutionize.</p>
<p>Case { Retail Store Business }</p>
<p>Assume that a data scientist was tasked to help the retail store stock the “right” quantity. By intuition, most “data scientists” consider the last X years of data for prediction. They may take various models from “simple averages” to “ARIMA” to “LSTM” and choose the best model based on the evaluation metrics like AIC or BIC, or MAPE. { Classic Time series modelling algorithms }</p>
<p>After this exercise, we will determine the quantity that could sell for the next period. Does it end here?</p>
<p>It would not, because we haven’t answered the business question of what should be the stock holding for the next period. i.e., how many goods should be stocked in the store?</p>
<p>Say, if we want to proceed with the model’s output itself. Since the model has inherent bias and variance, certain goods might get stocked out sooner, and others will not sell as predicted. { Alternatively, at times, the business could not procure the goods as indicated due to the cash flow constraint. Which we will discuss in other cases}</p>
<p>What happens if there is stock out; revenue drops. Alternatively, what happens if there is excess stock; cost increases. In both of these cases, the profit decreases.</p>
<p>Should we conclude that data science is not helping in this scenario? No, it isn’t.</p>
<p>It is just that it has not been adequately solutionized. So far, we have put the hat of “Machine Learning”, which needs to be started with the “Traditional Research” cap.</p>
<p>Under Traditional research, we may learn the following things: - Stock will come from warehouses every two days, for which the indent has to be shared a day earlier.</p>
<ul>
<li>In all case scenarios, a buffer or safety stock should be kept in the store for fast-moving items to avoid supply chain shocks.</li>
<li>Evading bull-whip effect, the probable forecast for certain goods must be shared with vendors for effective coordination.</li>
<li>A simulation must be constructed such that the stock at the store is not too high to avoid high business costs. Also, the store needs to maintain sufficient service levels(of the goods, i.e., stock availability) so the customer doesn’t face a bad experience.</li>
</ul>
<p>Based on these learnings, we will research any existing methodologies available to address these questions. Bingo!!</p>
<p>We would crack the solution by browsing the topics of Supply Chain Analytics or Operations Optimization.</p>
<p>Which will provide methods to arrive at Safety Stock, Re-order Level, Re-order Quantity and Service Levels.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/is-domain-knowledge-important/safety_stock.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="437"></p>
</figure>
</div>
<p>From here, we can use ML ( Time Series Modelling ) to arrive at tomorrow’s prediction and perform a simulation ( Monte Carlo Simulation ) to arrive at service levels for different clusters ( K-Means Clustering ) of products. These outputs are fed into the above solution we saw in “Traditional Research”.</p>
<p>Later we wear the “Software Development” hat to fine-tune the coding and keep the end-to-end pieces in hands-off mode.</p>
<p>In this way, Data Scientists must change hats to complete the work.</p>
<p>In this case, we can clearly see that the “Traditional Research” hat is hugely needed to understand the “lay of the land”. Else the entire modelling effort would have faced an identity crisis.</p>
<p>Is there any defined prescription or rules to understand the lay of the land? The answer is NO. The long answer is</p>
<ul>
<li>Curiosity to learn about the domain.</li>
<li>Asking the business the right questions.</li>
<li>Doing personal research as, at times, business is driven by perceptions or experience. { Only a “fresh eye” brings a new perspective } - Learning what others have done already. There would have been plenty of research already available. <span style="font-size: small;">{ There is no need for new IP in most of the scenarios }</span></li>
<li>Learning Consultant frameworks like BCG Matrix, Product Life Cycle, Customer Life Cycle, etc., will help us think on alternative perspectives.</li>
</ul>
<p>There are several examples that I have faced personally in my early data science career, which told me the hard way about the importance of domain knowledge. The above example is one such classic. Stay tuned for more Data science news.</p>
<script src="https://giscus.app/client.js" data-repo="ArunKoundinya/AIBasicswithAK" data-repo-id="R_kgDOLXPVRw" data-category="General" data-category-id="DIC_kwDOLXPVR84CdeVx" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="purple_dark" data-lang="en" crossorigin="anonymous" async="">
</script>



 ]]></description>
  <category>domain</category>
  <category>operations</category>
  <guid>https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/is-domain-knowledge-important/</guid>
  <pubDate>Tue, 25 Jul 2023 04:00:00 GMT</pubDate>
  <media:content url="https://arunkoundinya.github.io/AIBasicswithAK/blogs/posts/is-domain-knowledge-important/image.png" medium="image" type="image/png" height="131" width="144"/>
</item>
</channel>
</rss>
